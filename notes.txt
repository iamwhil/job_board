Greetings Alejandro!

As I'm not sure if you'll end up re-using this exercise ever, I've decided to create a "notes.txt" file for you, instead of documenting what I've done / progress in the README.md file.  This file will help to inform you to what things I've done and why I've done them, as well as allowing me to keep track of my thoughts and progress.

I normally operate in a time to completion order, doing the easiest tasks first (getting 20 easy things done looks/feels way more productive than getting 1 big thing done).  However I'm progressing through your request list in order.  

Initially bundle exec rake db:migrate:reset works, bundle exec rake db:seed fails.

Point 1 - Seeds:
It looks like you've used a bulk_insert gem, but in lieu of using gems (as we discussed), I'll do this by hand to show you how and why we sould do this. The idea is that inserting into a database in bulk is MUCH faster than doing the operations 1 at a time.

Also there is a check against the `random_skill = Random.rand(all_skills.length + 1)` generating 0.  The +1 should ensure this, as Random.rand(max_val) generates a random number between 0 and max_val.  However, I saw in the skill_ids (made from random_skill numbers), '0's popping up.

Fun fact - I put some tn-Time.now() in the seeds to see what the time difference between directly inserting into the database (my way) and using the gem.  You'll see a "their bulk input" and "Whil's bulk input" statements that I left in for fun.  Mine looks to be 36% faster on average. Woo! I'm saving you that time you busy man you!

Point 2 - Pagination:

I felt that the best way to go about the pagination was also to combine it with point #3 which reqeusts caching.  I've used Memcached (Which you should have on Mac and Linux systems) and the accompanying Dalli Gem (bundle install).  I have enabled it in the config/environments/development.rb, I did not enable it for production, as I doubt this is being deployed anywhere.  Enabling it in production, however, is much the same.  I've also assumed that the caches will remain static (no new jobs), for simplicity.  In a real environment, I would rebuild the cache after Jobs or Users were created, updated, or destroyed (I've since realized that this is going to be done on the admin side - however I'm sadly out of time).

The memcached.rb intializer builds the inital cache when the server is started up.  The keys are based on the class and then pagination, eg: :jobs_page1 or :users_page7, etc.  Arbitrarily I chose 10 items per page.  Because Memcached is not persistent, I've used .fetch() to retrieve the data.  If the data is not found in the cache it is rebuilt.  If the page is requested out of range, eg. jobs_page70 (Jobs 700 to 709) an empty array is returned.

Point 2 requests for the users#index to be paginated.  However, there was no controller for users or the accompanying views.  How do you make these?! Just kidding - controller generated and views created.  Additionally the index route was created for the users resources.

To use the pagination, send the "page" as a parameter to the index.  
Eg. `/jobs/?page=2`

Point 3 - A fuzzier search.

Caching has been implemented mostly in point 2, and the Memcached / Dalli implementation continues to be used here.

The search has been made less strict by searching the jobs based on the terms in the title or the description.  This has been implemented by creating and then caching a hash where the keys are the terms, and the values are the job ids.  When a search is performed, the search terms are separated by white space, and then the hash's keys are searched for the individual terms.  If the term is found in the hash, the Jobs are returned where the ids match the values in the hash.

The Jobs returned from a search are not paginated as they do not fit the cache / pagination workflow I implemented.

The search functionality follows the previously built functionality (and white space formatting).  To use the search send either or both the 'title' or 'description' parameters.  Jobs with the matching title terms will be returned first.
Examples:
title only search: `/jobs/?title=programmer` or `/jobs/?title=programmer accountant`
description only search: `/jobs/?description=ipsum`
title & description search:  `/jobs/?title=Programmer Accountant&description=ipsum`

Point 4 - Filtering.

The filtering of jobs based on skills requires for the person filtering their results to know the title of the JobSkills.  I've implemented the filtering by taking all of the filter terms (comma separated - as terms can have white space), and then finding all possible jobs that have those terms.  Then based on the current jobs that match search criteria or pagination, filtered out the jobs not found in the possible jobs.

To expedite finding JobSkills based on their titles, I have indexed the JobSkill titles (new migration).

Filtering a paginated result was resulting in 0 - 1 jobs being displayed.  This was not very useful.  Thus if the filtering is requested, but there are no search terms, pagination is ignored and all jobs that match the filtered request are shown.

Examples: 
with search: `/jobs/?title=programmer&filter=NIR Spectroscopy`
no search: `/jobs/?filter=legal issues`
multiple terms: `/jobs/?filter=NIR Spectroscopy,legal issues`

Hour 6 discussion:

    Alejandro, thanks for taking the time to look over my work.  I hope that it has given you a decent feel for how I work through a program and what my coding looks like.  I've tried to make the work I've done perform a solidly as possible.  With more time I'm positive we could be rolling in free Microsoft Office software!  If you have any feedback that would be awesome, I'm alway looking to improve my skills! Thanks.

    Unfortunately I'm at the 6 hour mark (a little bit over), and have pile of work I currently need to do for SafetySpot, which amassed up while we were furloughed last week!  I've tried to briefly address the points I was unable to get to below.

	Ideally I would make the filtering more user friendly by making the filter terms less strict.  This could also be sped up by caching a hash with title terms as keys and an array of JobSkill id's as the values. Finding the JobSkills would function roughly the same as the title and description search.

	Point 5 - Incomplete - Only allow 'admins' to access my admin namespace.

	To complete this I would utilize sessions and force the user to login before accessing the admin side.  This would be done with a before_action filter on the admin controller.  If the authentication failed I would return an error and let the client's browser / API interface notify the user.

	Point 6 - Incomplete - In order to match Users to Jobs I'll need Users to be able to set their job skills too.

	Again here I would like to add a password field to the user and create a session for the user if they log in.  I would then have a JobSkill controller with before_action filters to check the session, which would allow authenticated users to set their job skills.  Non-authenticated users would again receive error messages.

	Point 7 - Incomplete - admin/matched_jobs#idx isn't the most efficient method nor is UserJobMatch the most well thought out (or actually functioning) match score. What changes would you make given the information we have?

	Given the information at hand, admin/matched_jobs is not a controller!  However the matched_jobs is a controller, and digging through the UserJobMatch, the quickest way I see to vastly improve the match score is to have the running summ be a total of the JobSkillConnection's importance instead of just a +1 if the skill is present.

	Point 8 - Incomplete - Our admins would love to get a list of which users match a specific job. That way we can do something with recruiters cause they like that sorta thing.

	On the admin/matched_jobs I would create a "report" method, and a cooresponding route in the routes.  When requested it would send back a list of users which match a specific job and their match score, ordered by the match score.